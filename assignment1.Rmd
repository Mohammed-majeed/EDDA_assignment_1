---
title: "Assignment 1"
author: "Group 61"
date: "23 February 2023"
output: pdf_document
highlight: tango
---

*In order not to be bothered with rounding the numbers, set `options(digits=3)r options(digits=3)`.*

## Exercise 1

Read the data

```{r echo=FALSE}
birthweight = read.table(file = "birthweight.txt", header = TRUE)
data= birthweight$birthweight

```

**a)** Check for normality with QQ plot,histogram, and boxplot

```{r}
qqnorm(data, main = "Normal Q-Q Plot of Birthweight")

# Check for normality with histogram
hist(x = data,breaks=15,main = "Histogram of Birthweights",
     xlab = " Birthweight ",freq = FALSE)
lines(x= density(x= data), col=" red ")

# Check for normality with boxplot
boxplot (data , main =" Boxplot of Birthweight ",
         xlab =" Birthweight ")#horizontal = TRUE)

```

calculate Shapiro-Wilk normality test

```{r}
shapiro.test(data)
```

Upon observation, the density displays a bell-shaped curve that closely resembles a normal distribution. The QQ-plot also appears to follow a straight line, indicating normality of the data. The boxplot exhibits some asymmetry, but with few outliers, it can still be assumed that the data is normally distributed. It is worth noting, however, that the histogram, QQ-plot, and boxplot show some variability, which may be attributed to the sample size. A larger sample size would likely result in less variability in these graphs. Additionally, the Shapiro-Wilk test for normality yields a non-significant result with a p-value of 0.90, suggesting that the null hypothesis cannot be rejected, and that the sample follows a normal distribution. Considering these findings, we can assume that the birth weights adhere to a normal distribution.

```{r}
# construct Confidence Interval
mu <- mean(data)
stnd <-sd(data)
CI <- 0.96
alpha <- 1-CI
# Calculate the margin of error for a 95% confidence interval
z <- qnorm(1 - alpha/2) # 98th percentile of standard normal distribution
# Calculate the margin of error
me <- z * stnd / sqrt(length(data))
# Calculate the confidence interval
lower_ci = mu - me
upper_ci = mu + me
# Print the confidence interval
cat("Confidence Interval: [", lower_ci, ", ", upper_ci, "]", sep = "")
```

```{r}
# construct a bounded 96%-CI for mu(mean) 
for (sample_size in 1:1000) {
  lower_bound = mu - z*stnd/sqrt(sample_size)
  upper_bound = mu + z*stnd/sqrt(sample_size)
  CI_length <- upper_bound - lower_bound
  if (CI_length <= 100) {
    break
  }
}
cat("sample_size",sample_size)
```

In order to achieve a confidence interval with a maximum length of 100, a minimum sample size of 821 is required.

```{r}
# Compute a bootstrap 96%-CI for mu and compare it to the above CI.
library(boot)
B <- 1000 # Choose number of bootstrap resamples
boot_data <- boot(data, statistic = function(data, i) mean(data[i]), R = B)
boot_ci <- boot.ci(boot_data, type = "perc", conf = 0.96)
lower_bound_boot_ci <- boot_ci$percent[[4]]
upper_bound_boot_ci <- boot_ci$percent[[5]]
cat("boot_CI Confidence Interval: [", lower_bound_boot_ci, ", ", upper_bound_boot_ci, "]", sep = "")
```

Since the sample is assumed to follow a normal distribution, the bootstrapped confidence interval is expected to be similar to the confidence interval calculated prior. This is because the sample mean is a consistent estimator of the population mean, and the bootstrapping method is based on resampling the data with replacement from the original sample.

**B)**

```{r}
# Verify this claim by using a one side t-test
t.test(data, mu = 2800, alternative = "greater")
```

performed a one-sample t-test with the null hypothesis(H0) that the mean birthweight is equal to 2800 grams (mu = 2800) and the alternative hypothesis(H1) that the mean birthweight is greater than 2800 grams.The p-value is less than the conventional significance level of 0.05, which indicates strong evidence against the null hypothesis. Therefore, we reject the null hypothesis and conclude that the mean birthweight is significantly greater than 2800 grams. The confidence interval (CI) in the R-output for this test represents a range of values within which the true population mean birthweight is likely to fall with a certain degree of confidence.

```{r}
# sign test
binom.test(sum(data > 2800), n=length(data), p = 0.5, alternative = "greater")
```

The p-value is less than the conventional significance level of 0.05, which indicates strong evidence against the null hypothesis. Therefore, we reject the null hypothesis and conclude that the mean birthweight is significantly greater than 2800 grams.

**C)**

the powers of the t-test and sing

```{r}
B = 1000; n = 50
psign = numeric(B) # will contain P-values of sign test
pttest = numeric(B) # will contain P-values of T test
for(i in 1:B) {
  x = sample(data, n)
  pttest[i] = t.test(x, mu=2800, alt='g')[[3]] # extract P-value
  psign[i] = binom.test(sum(x>2800), n, alt='g')[[3]] # extract P-value
}
power_ttest = sum(pttest<0.05)/B
power_sign = sum(psign<0.05)/B
cat("the powers of the t-test: ", power_ttest, ",  the powers of the sing test: ", power_sign, sep = "")
```

One way to compute the power of the two tests is through simulation. Assuming the alternative hypothesis to be that the true mean is greater than 2800, a mean can be randomly sampled from a normal distribution within the range of (2800, max(birthweight)]. This mean can then be used to generate a sample X\^ and perform both statistical tests, testing its sample mean X\^ against the hypothesis that the true mean is greater than 2800. By calculating the proportion of times each test correctly rejected the null hypothesis, the power of the tests can be determined. It is anticipated that the t-test will have greater power than the sign test as it assumes a normal distribution of the sample, while the sign test discards significant information. Although the sign test is more resilient than the t-test, its power is reduced in cases where assumptions are not violated.

**D)** Recover the whole confidence interval and its confidence level.

```{r}
# Set the number of samples to take and the lower probability
n_samples = 100
p_left = 0.25
# Create an empty vector to store the sample probabilities
sample_probabilities = numeric(n_samples)
# Take n_samples samples of size n_samples from the birthweight vector
# Calculate the proportion of samples that have a weight less than 2600 grams
# Store the sample proportion in the sample_probabilities vector
for(i in 1:n_samples){
  sample = sample(data, n_samples, replace = TRUE)
  sample_probabilities[i] = sum(sample < 2600)/n_samples
}
# Calculate the standard deviation of the sample proportions
sample_sd = sd(sample_probabilities)
# Calculate the mean of the sample proportions
p_hat = mean(sample_probabilities)
# margin of error 
me = p_hat - p_left
# Calculate the upper confidence interval for p
p_right = p_hat + me
confidence_level = ((me/1.96)*2)-1
cat("Confidence Interval: [", p_left, ", ", p_right, "]","confidence_level: ",confidence_level , sep = "")
```

sample proportion denoted as pË†, we can calculate the right side of the confidence interval using the margin of error. As a result, we obtain the confidence interval [0.25, 0.4] with a confidence level of around 92%.

**E)**

```{r}
male_means = c()
female_means = c()

for (i in 1:1000) {
  # Select 34 males and 28 females with birthweight < 2600 g
  male_2600 = sample(data< 2600, 34)
  female_2600 = sample(data[data < 2600], 28)
   # Select 61 males and 65 females with birthweight >= 2600 g
  male_others = sample(data[data >= 2600], 61)
  female_others = sample(data[data >= 2600], 65)
   # Combine the selected males and females with birthweight < 2600 g
  males = c(male_2600, male_others)
  females = c(female_2600, female_others)
  # Calculate the mean birthweight for males and females
  male_means = c(male_means, mean(males))
  female_means = c(female_means, mean(females))
}
# Calculate the mean of the sample means for males and females
mean(male_means)
mean(female_means)
# Perform a two-sample t-test assuming unequal variances
t.test(male_means, female_means)
```

A Two-sample t-test was conducted to examine whether the mean weight differs for male and female babies. The null hypothesis (H0) assumed that the mean weight is different, while the alternative hypothesis (H1) assumed that it is not different for male and female babies. The obtained p-value was lower than the conventional significance level of 0.05, indicating strong evidence against the null hypothesis. As a result, the null hypothesis was rejected, and it was concluded that the mean weight is not different for male and female babies.

## Exercise 2

## Exercise 3

```{r echo=FALSE}
data = read.table(file = "diet.txt", header = TRUE)
```

First, we add the response variable weight.lost.

```{r}
data$weight.lost=data$preweight-data$weight6weeks

```

**a)**

Both histograms do not look normal, but the difference of after-before from the Shapiro test does mostly look normal. So we can use the paired t-test. According to the t-test, the diet does affect the weight loss because of a p-value \< 2.2e-16.

```{r echo=FALSE}
before=data$preweight;after=data$weight6weeks
par(mfrow=c(1,2))


qqnorm(before)
hist(before) 
qqnorm(after)
hist(after) 
qqnorm(after-before)
hist(after-before) 
t.test(before,after,paired=T) 
```

**b)**

We perform one-way ANOVA and it gives a p-value of 0.003. This means that diet has an effect on weight loss.

```{r, fig.width=6,fig.height=3.5,collapse=TRUE}
data$diet=factor(data$diet) 
dataaov=lm(weight.lost~diet,data=data)
anova(dataaov)
```

We will check the assumptions. We perform a QQ-plot with the residuals for normality. The QQ-plot looks normal. The fitted values plot also does not really show a pattern.

```{r, fig.width=6,fig.height=3.5,collapse=TRUE}
par(mfrow=c(1,2)); qqnorm(residuals(dataaov)) 
plot(fitted(dataaov),residuals(dataaov)) 
```

We use the summary to be able to check the estimates. The group means are all \>0, which means that the diets lead to weight loss and diet 3 is the best for losing weight.

```{r, fig.width=6,fig.height=3.5,collapse=TRUE}

summary(dataaov) #can we use fitted(dataaov here as well? )

```

**c)** The two-way ANOVA test shows that diet and gender have an effect on the lost weight. The p-value of 0.049, shows that there is not a significant interaction between diet and gender.

```{r, fig.width=6,fig.height=3.5,collapse=TRUE}
genderaov=lm(weight.lost~gender*diet,data=data)  
anova(genderaov) 
```

**e)**

We prefer b, because we think diet and lost weight are the most relevant variables. Gender is a "fixed" variable which you cannot really change that easily.

The predicted weight loss for all diets: 3.300kg, 3.026kg and 5.148kg

```{r, fig.width=6,fig.height=3.5,collapse=TRUE}
preddata=data.frame(diet=c("1","2","3"))
predict(dataaov,preddata) 
 

```

## Exercise 4

Load the MASS package and view the npk dataset

```{r echo=FALSE}
library(MASS)
data(npk)
```

**A)**

```{r}
#Create a matrix of random plots
random_plots_matrix <- cbind(rep(1:24),rep(1:6, each = 4),
                             replicate(3, c(replicate(6, sample(c(1,1,0,0))))))
#Convert the matrix to a data frame
data_frame <- data.frame(random_plots_matrix)
#Set column names
header <- c("plot", "block", "N", "P", "K")
colnames(data_frame) <- header
#View the resulting data frame
head(data_frame)
```

**B)**

```{r}
# Subset the data to only include nitrogen treatment
npk_nitrogen  <- npk[npk$N == 1,]
# Calculate the average yield per block for nitrogen treatment
nitrogen_avg_yield  <- aggregate(yield ~ block, data = npk_nitrogen, FUN = mean)
# Subset the data to only include plots without nitrogen treatment
npk_no_nitrogen  <- npk[npk$N == 0,]
# Calculate the average yield per block for plots without nitrogen treatment
no_nitrogen_avg_yield  <- aggregate(yield ~ block, data = npk_no_nitrogen, FUN = mean)
# Make a boxplot comparing the average yield per block for nitrogen and no nitrogen treatments
boxplot(no_nitrogen_avg_yield$yield, nitrogen_avg_yield$yield, 
        names = c("No Nitrogen Treatment", "Nitrogen Treatment"), ylab = "yield")
#legend("topleft", legend = c("Nitrogen Treatment", "No Nitrogen Treatment"))
ddf = structure(list(no_nitrogen_avg_yield$yield,nitrogen_avg_yield$yield),
                .Names = c("No Nitrogen Treatment", "Nitrogen Treatment"), class = "data.frame")
barplot(c(no_nitrogen_avg_yield$yield,nitrogen_avg_yield$yield),
        col = c("#1b98e0", "#353436"),beside = TRUE, xlab="blocks",ylab = "yield",
        ylim=c(0,90))
axis(side = 1, at = 1.5, labels =( "1"))
axis(side = 1, at = 4, labels =( "2"))
axis(side = 1, at = 6.5, labels =( "3"))
axis(side = 1, at = 9, labels =( "4"))
axis(side = 1, at = 11.5, labels =( "5"))
axis(side = 1, at = 13.5, labels =( "6"))
legend("topright", legend = c("Nitrogen Treatment", "No Nitrogen Treatment"),
       fill = c("#1b98e0", "#353436"))
```

**C)**

```{r}
fit <- aov(yield ~ block + N, data = npk)
summary(fit)
```

The output of the ANOVA analysis indicates that both factors (block and N) have a significant effect on the yield.The p-value for block is 0.0262, which is less than 0.05, indicating a significant effect of block on yield. The p-value for N is 0.0071, which is also less than 0.05, indicating a significant effect of N on yield.

The F-value for block is 3.395, which is relatively small compared to the F-value for N (9.360), suggesting that the effect of block on yield is smaller than the effect of N.

The residual sum of squares is 343.8, indicating the variability of the data points around the fitted model.

In conclusion, it was sensible to include factor block in the model as it has a significant effect on yield. The Friedman test cannot be applied in this case since there is only one observation per combination of block and N.
